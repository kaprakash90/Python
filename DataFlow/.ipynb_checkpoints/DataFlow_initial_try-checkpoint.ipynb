{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.dataflow as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.Pipeline('DirectPipelineRunner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PValue transform=<_NativeWrite(PTransform) label=[native_write]> at 0x1061cd850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p | df.Create(['hello', 'world']) | df.io.Write(df.io.TextFileSink('./test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.dataflow.runners.direct_runner.DirectPipelineResult at 0x106188e90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\u001b=\n",
      "world\n",
      "\u001b[K\u001b[?1l\u001b>.txt (END)\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!more ./test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = './datain'\n",
    "output_file = './dataout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Timestamp\": 1528437211.152227, \"Price\": 60, \"ProductName\": \"soft_drink_1l\", \"ProductID\": 1}\r\n",
      "{\"Timestamp\": 1528437211.152303, \"Price\": 250, \"ProductName\": \"shorts\", \"ProductID\": 2}\r\n",
      "{\"Timestamp\": 1528437211.152328, \"Price\": 120, \"ProductName\": \"face_wash\", \"ProductID\": 3}\r\n"
     ]
    }
   ],
   "source": [
    "def generate_data(outfile, size):\n",
    "    import json\n",
    "    import time\n",
    "    product = {'milk':20, 'soft_drink_300ml':35, 'soft_drink_500ml':45, 'soft_drink_1l':60, 'beer':80, 'snacks':50, 'sweets':100, 'candy':30,'rice':60, 'dhal':70,'shampoo':96, 'soap':20,'face_wash':120,'chicken':200,'mutton':600, 'shirt':400, 'pant':600, 'shorts':250, 'salvar':700, 'shoe':300,'flipflop':100}\n",
    "    with open(outfile, 'wt') as f:  \n",
    "        for _ in xrange(size):\n",
    "            for num, ix in enumerate(product):\n",
    "                f.write('%s\\n' % json.dumps(\n",
    "                        {'ProductID': 1 + num, 'ProductName': ix, \n",
    "                         'Price': product[ix], 'Timestamp': time.time()}))\n",
    "\n",
    "generate_data(input_file, 100)\n",
    "!head -3 $input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.dataflow as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.Pipeline('DirectPipelineRunner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PValue transform=<_NativeWrite(PTransform) label=[native_write]> at 0x106188c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p \n",
    "   |df.io.Read(df.io.TextFileSource(input_file))\n",
    "   | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.dataflow.runners.direct_runner.DirectPipelineResult at 0x106638b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Timestamp\": 1528437211.152227, \"Price\": 60, \"ProductName\": \"soft_drink_1l\", \"ProductID\": 1}\r\n",
      "{\"Timestamp\": 1528437211.152303, \"Price\": 250, \"ProductName\": \"shorts\", \"ProductID\": 2}\r\n",
      "{\"Timestamp\": 1528437211.152328, \"Price\": 120, \"ProductName\": \"face_wash\", \"ProductID\": 3}\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = (\n",
    "    df.io.Read(df.io.TextFileSource(input_file))\n",
    "    | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Timestamp\": 1528437211.152227, \"Price\": 60, \"ProductName\": \"soft_drink_1l\", \"ProductID\": 1}\r\n",
      "{\"Timestamp\": 1528437211.152303, \"Price\": 250, \"ProductName\": \"shorts\", \"ProductID\": 2}\r\n",
      "{\"Timestamp\": 1528437211.152328, \"Price\": 120, \"ProductName\": \"face_wash\", \"ProductID\": 3}\r\n"
     ]
    }
   ],
   "source": [
    "p = df.Pipeline('DirectPipelineRunner')\n",
    "p | graph\n",
    "p.run()\n",
    "!head -3 $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def dataflow_run(line, cell):\n",
    "    p = df.Pipeline('DirectPipelineRunner')\n",
    "    p | eval(cell)\n",
    "    p.run()\n",
    "    !head -3 $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Timestamp\": 1528437211.152227, \"Price\": 60, \"ProductName\": \"soft_drink_1l\", \"ProductID\": 1}\r\n",
      "{\"Timestamp\": 1528437211.152303, \"Price\": 250, \"ProductName\": \"shorts\", \"ProductID\": 2}\r\n",
      "{\"Timestamp\": 1528437211.152328, \"Price\": 120, \"ProductName\": \"face_wash\", \"ProductID\": 3}\r\n"
     ]
    }
   ],
   "source": [
    "%%dataflow_run\n",
    "(df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(e):\n",
    "    import json\n",
    "    r = json.loads(e)\n",
    "    return r['ProductID'], r['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\r\n",
      "(2, 250)\r\n",
      "(3, 120)\r\n"
     ]
    }
   ],
   "source": [
    "%%dataflow_run\n",
    "(df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.Map(parse_record)\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(e):\n",
    "    import json\n",
    "    r = json.loads(e)\n",
    "    yield r['ProductID'], r['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\r\n",
      "(2, 250)\r\n",
      "(3, 120)\r\n"
     ]
    }
   ],
   "source": [
    "%%dataflow_run\n",
    "(df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.FlatMap(parse_record)\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseRecordDoFn(df.DoFn):\n",
    "    def process(self, context):\n",
    "        import json\n",
    "        r = json.loads(context.element)\n",
    "        yield r['ProductID'], r['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\r\n",
      "(2, 250)\r\n",
      "(3, 120)\r\n"
     ]
    }
   ],
   "source": [
    "%%dataflow_run\n",
    "(df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.ParDo(ParseRecordDoFn())\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, [50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50])\r\n",
      "(12, [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30])\r\n",
      "(8, [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20])\r\n"
     ]
    }
   ],
   "source": [
    "%%dataflow_run\n",
    "(df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.ParDo(ParseRecordDoFn())\n",
    " | df.GroupByKey()\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "def parse_record(e, filtered):\n",
    "    import json\n",
    "    r = json.loads(e)\n",
    "    if int(r['ProductID']) not in filtered:\n",
    "        yield r['ProductID'], r['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100000)\r\n",
      "(1, 100000)\r\n"
     ]
    }
   ],
   "source": [
    "%%dataflow_run\n",
    "(df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.FlatMap(parse_record, filtered)\n",
    " | df.CombinePerKey(sum)\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.dataflow import pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100000)\r\n",
      "(1, 100000)\r\n"
     ]
    }
   ],
   "source": [
    "p = df.Pipeline('DirectPipelineRunner')\n",
    "filtered_pcoll = p | df.Create(filtered)\n",
    "(p \n",
    " | df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.FlatMap(parse_record, pvalue.AsIter(filtered_pcoll))\n",
    " | df.CombinePerKey(sum)\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))\n",
    "\n",
    "p.run()\n",
    "!head -3 $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PCollection transform=<Create(PTransform) label=[Create]> at 0x10cde3ad0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pcoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 200000)\r\n",
      "(8, 200000)\r\n",
      "(5, 200000)\r\n"
     ]
    }
   ],
   "source": [
    "p = df.Pipeline('DirectPipelineRunner')\n",
    "pc1 = p | df.io.Read('Read once', df.io.TextFileSource(input_file)) \n",
    "pc2 = p | df.io.Read('Read twice', df.io.TextFileSource(input_file)) \n",
    "\n",
    "((pc1, pc2) \n",
    " | df.Flatten()\n",
    " | df.FlatMap(parse_record, filtered=[])\n",
    " | df.CombinePerKey(sum)\n",
    " | df.io.Write(df.io.TextFileSink(output_file)))\n",
    "\n",
    "p.run()\n",
    "!head -3 $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = 'silviuc-dataflow:demo.silviuc_demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:The gcloud tool was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/internal/auth.py\", line 104, in _refresh\n",
      "    ['gcloud', 'auth', 'print-access-token'], stdout=processes.PIPE)\n",
      "  File \"/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/utils/processes.py\", line 49, in Popen\n",
      "    return subprocess.Popen(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/python2/lib/python2.7/subprocess.py\", line 394, in __init__\n",
      "    errread, errwrite)\n",
      "  File \"/anaconda3/envs/python2/lib/python2.7/subprocess.py\", line 1047, in _execute_child\n",
      "    raise child_exception\n",
      "OSError: [Errno 2] No such file or directory\n",
      "ERROR:root:Error while visiting Write/native_write\n"
     ]
    },
    {
     "ename": "AuthenticationException",
     "evalue": "The gcloud tool was not found: [Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f77cbcc84e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             write_disposition=df.io.BigQueryDisposition.WRITE_TRUNCATE))) \n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Resulting BigQuery table:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'https://bigquery.cloud.google.com/table/%s?pli=1'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutput_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/pipeline.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/runners/direct_runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline, node)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDirectPipelineRunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final: Debug counters: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_counters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     return DirectPipelineResult(state=PipelineState.DONE,\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/runners/runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline, node)\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunVisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor, node)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mstart_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mstart_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor, pipeline, visited)\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor, pipeline, visited)\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor, pipeline, visited)\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# Visit the outputs (one or more). It is essential to mark as visited the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/runners/runner.pyc\u001b[0m in \u001b[0;36mvisit_transform\u001b[0;34m(self, transform_node)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mvisit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m           \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error while visiting %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/runners/runner.pyc\u001b[0m in \u001b[0;36mrun_transform\u001b[0;34m(self, transform_node)\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'run_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    157\u001b[0m         'Execution of [%s] not implemented in runner %s.' % (\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/runners/direct_runner.pyc\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[0;34m(self, pvalue, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/runners/direct_runner.pyc\u001b[0m in \u001b[0;36mrun__NativeWrite\u001b[0;34m(self, transform_node)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0msink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0msink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_counters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'element_counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/io/bigquery.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m     self.client.get_or_create_table(\n\u001b[1;32m    545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         self.sink.create_disposition, self.sink.write_disposition)\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/io/bigquery.pyc\u001b[0m in \u001b[0;36mget_or_create_table\u001b[0;34m(self, project_id, dataset_id, table_id, schema, create_disposition, write_disposition)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0mfound_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m       \u001b[0mfound_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mexn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/utils/retry.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexn\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretry_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/io/bigquery.pyc\u001b[0m in \u001b[0;36m_get_table\u001b[0;34m(self, project_id, dataset_id, table_id)\u001b[0m\n\u001b[1;32m    632\u001b[0m     request = bigquery.BigqueryTablesGetRequest(\n\u001b[1;32m    633\u001b[0m         projectId=project_id, datasetId=dataset_id, tableId=table_id)\n\u001b[0;32m--> 634\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m     \u001b[0;31m# The response is a bigquery.Table instance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/google/cloud/dataflow/internal/clients/bigquery/bigquery_v2_client.pyc\u001b[0m in \u001b[0;36mGet\u001b[0;34m(self, request, global_params)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetMethodConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Get'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       return self._RunMethod(\n\u001b[0;32m--> 590\u001b[0;31m           config, request, global_params=global_params)\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mInsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/apitools/base/py/base_api.pyc\u001b[0m in \u001b[0;36m_RunMethod\u001b[0;34m(self, method_config, request, global_params, upload, upload_config, download)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mopts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retry_func'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             http_response = http_wrapper.MakeRequest(\n\u001b[0;32m--> 720\u001b[0;31m                 http, http_request, **opts)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessHttpResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/apitools/base/py/http_wrapper.pyc\u001b[0m in \u001b[0;36mMakeRequest\u001b[0;34m(http, http_request, retries, max_retry_wait, redirections, retry_func, check_response_func)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mtotal_wait_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfirst_req_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 retry_func(ExceptionRetryArgs(http, http_request, e, retry,\n\u001b[0;32m--> 356\u001b[0;31m                                               max_retry_wait, total_wait_sec))\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python2/lib/python2.7/site-packages/apitools/base/py/http_wrapper.pyc\u001b[0m in \u001b[0;36mHandleExceptionsAndRebuildHttpConnections\u001b[0;34m(retry_args)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mretry_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretry_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0mRebuildHttpConnections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     logging.debug('Retrying request to url %s after exception %s',\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: The gcloud tool was not found: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "p = df.Pipeline('DirectPipelineRunner')\n",
    "(p \n",
    " | df.io.Read(df.io.TextFileSource(input_file))\n",
    " | df.FlatMap(parse_record, pvalue.AsIter(filtered_pcoll))\n",
    " | df.CombinePerKey(sum)\n",
    " | df.Map(lambda (pr, v): {'ProductID': pr, 'Value': v}) \n",
    " | df.io.Write(df.io.BigQuerySink(\n",
    "            output_table,\n",
    "            schema='ProductID:INTEGER, Value:FLOAT', \n",
    "            create_disposition=df.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "            write_disposition=df.io.BigQueryDisposition.WRITE_TRUNCATE))) \n",
    "\n",
    "p.run()\n",
    "print 'Resulting BigQuery table:'\n",
    "print 'https://bigquery.cloud.google.com/table/%s?pli=1' % output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
